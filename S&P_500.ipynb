{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S&P 500.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNkIWFCFcfwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 載入套件\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMp7lxNNjTsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 載入訓練、測試資料\n",
        "\n",
        "SP_train = pd.read_csv('S&P500 training.csv')\n",
        "SP_test = pd.read_csv('S&P500 testing.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Y-evfPyw2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定義目標變數(四個交易日後的收盤價與今日收盤價比較，大於今日收盤價為1，小於為0)\n",
        "\n",
        "SP_train['fourday_trend'] = np.where(SP_train['Close Price'].shift(-4) > SP_train['Close Price'], 1, 0)\n",
        "\n",
        "SP_test['fourday_trend'] = np.where(SP_test['Close Price'].shift(-4) > SP_test['Close Price'], 1, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAfvsUc2kSFg",
        "colab_type": "text"
      },
      "source": [
        "#EDA 資料探索\n",
        "\n",
        "**進行資料基本內容探索**\n",
        "\n",
        "**從以下資料探索中可以得知資料並不需要進行預處理，主要有幾個原因:**\n",
        "\n",
        "**1.資料並為缺失值**\n",
        "\n",
        "**2.資料並無類別數據需要處理**\n",
        "\n",
        "**3.資料單位相同不需要進行標準化**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwk7eH9TkfnD",
        "colab_type": "code",
        "outputId": "ec0fab3c-077f-405a-d0a0-00a2b16d977e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "SP_train.tail(20)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open Price</th>\n",
              "      <th>Close Price</th>\n",
              "      <th>High Price</th>\n",
              "      <th>Low Price</th>\n",
              "      <th>Volume</th>\n",
              "      <th>fourday_trend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2244</th>\n",
              "      <td>01-Dec-2017</td>\n",
              "      <td>2645.10</td>\n",
              "      <td>2642.22</td>\n",
              "      <td>2650.62</td>\n",
              "      <td>2605.52</td>\n",
              "      <td>2458475264</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2245</th>\n",
              "      <td>04-Dec-2017</td>\n",
              "      <td>2657.19</td>\n",
              "      <td>2639.44</td>\n",
              "      <td>2665.19</td>\n",
              "      <td>2639.03</td>\n",
              "      <td>2693446656</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2246</th>\n",
              "      <td>05-Dec-2017</td>\n",
              "      <td>2639.78</td>\n",
              "      <td>2629.57</td>\n",
              "      <td>2648.72</td>\n",
              "      <td>2627.73</td>\n",
              "      <td>2194970112</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2247</th>\n",
              "      <td>06-Dec-2017</td>\n",
              "      <td>2626.24</td>\n",
              "      <td>2629.27</td>\n",
              "      <td>2634.41</td>\n",
              "      <td>2624.75</td>\n",
              "      <td>1903629696</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>07-Dec-2017</td>\n",
              "      <td>2628.38</td>\n",
              "      <td>2636.98</td>\n",
              "      <td>2640.99</td>\n",
              "      <td>2626.53</td>\n",
              "      <td>1933267328</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2249</th>\n",
              "      <td>08-Dec-2017</td>\n",
              "      <td>2646.21</td>\n",
              "      <td>2651.50</td>\n",
              "      <td>2651.65</td>\n",
              "      <td>2644.10</td>\n",
              "      <td>1810793472</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2250</th>\n",
              "      <td>11-Dec-2017</td>\n",
              "      <td>2652.19</td>\n",
              "      <td>2659.99</td>\n",
              "      <td>2660.33</td>\n",
              "      <td>2651.47</td>\n",
              "      <td>1775251584</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2251</th>\n",
              "      <td>12-Dec-2017</td>\n",
              "      <td>2661.73</td>\n",
              "      <td>2664.11</td>\n",
              "      <td>2669.72</td>\n",
              "      <td>2659.78</td>\n",
              "      <td>1977181824</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2252</th>\n",
              "      <td>13-Dec-2017</td>\n",
              "      <td>2667.59</td>\n",
              "      <td>2662.85</td>\n",
              "      <td>2671.88</td>\n",
              "      <td>2662.85</td>\n",
              "      <td>1931148416</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2253</th>\n",
              "      <td>14-Dec-2017</td>\n",
              "      <td>2665.87</td>\n",
              "      <td>2652.01</td>\n",
              "      <td>2668.09</td>\n",
              "      <td>2652.01</td>\n",
              "      <td>1974812928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2254</th>\n",
              "      <td>15-Dec-2017</td>\n",
              "      <td>2660.63</td>\n",
              "      <td>2675.81</td>\n",
              "      <td>2679.63</td>\n",
              "      <td>2659.14</td>\n",
              "      <td>3472946176</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2255</th>\n",
              "      <td>18-Dec-2017</td>\n",
              "      <td>2685.92</td>\n",
              "      <td>2690.16</td>\n",
              "      <td>2694.97</td>\n",
              "      <td>2685.92</td>\n",
              "      <td>2092151424</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2256</th>\n",
              "      <td>19-Dec-2017</td>\n",
              "      <td>2692.71</td>\n",
              "      <td>2681.47</td>\n",
              "      <td>2694.44</td>\n",
              "      <td>2680.74</td>\n",
              "      <td>1907656576</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2257</th>\n",
              "      <td>20-Dec-2017</td>\n",
              "      <td>2688.18</td>\n",
              "      <td>2679.25</td>\n",
              "      <td>2691.01</td>\n",
              "      <td>2676.11</td>\n",
              "      <td>1937403264</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2258</th>\n",
              "      <td>21-Dec-2017</td>\n",
              "      <td>2683.02</td>\n",
              "      <td>2684.57</td>\n",
              "      <td>2692.64</td>\n",
              "      <td>2682.40</td>\n",
              "      <td>1933795072</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2259</th>\n",
              "      <td>22-Dec-2017</td>\n",
              "      <td>2684.22</td>\n",
              "      <td>2683.34</td>\n",
              "      <td>2685.35</td>\n",
              "      <td>2678.13</td>\n",
              "      <td>1383888512</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2260</th>\n",
              "      <td>26-Dec-2017</td>\n",
              "      <td>2679.09</td>\n",
              "      <td>2680.50</td>\n",
              "      <td>2682.74</td>\n",
              "      <td>2677.96</td>\n",
              "      <td>1103808384</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2261</th>\n",
              "      <td>27-Dec-2017</td>\n",
              "      <td>2682.10</td>\n",
              "      <td>2682.62</td>\n",
              "      <td>2685.64</td>\n",
              "      <td>2678.91</td>\n",
              "      <td>1149108352</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>28-Dec-2017</td>\n",
              "      <td>2686.10</td>\n",
              "      <td>2687.54</td>\n",
              "      <td>2687.66</td>\n",
              "      <td>2682.69</td>\n",
              "      <td>1126089856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2263</th>\n",
              "      <td>29-Dec-2017</td>\n",
              "      <td>2689.15</td>\n",
              "      <td>2673.61</td>\n",
              "      <td>2692.12</td>\n",
              "      <td>2673.61</td>\n",
              "      <td>1332374016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date  Open Price  ...      Volume  fourday_trend\n",
              "2244  01-Dec-2017     2645.10  ...  2458475264              0\n",
              "2245  04-Dec-2017     2657.19  ...  2693446656              1\n",
              "2246  05-Dec-2017     2639.78  ...  2194970112              1\n",
              "2247  06-Dec-2017     2626.24  ...  1903629696              1\n",
              "2248  07-Dec-2017     2628.38  ...  1933267328              1\n",
              "2249  08-Dec-2017     2646.21  ...  1810793472              1\n",
              "2250  11-Dec-2017     2652.19  ...  1775251584              1\n",
              "2251  12-Dec-2017     2661.73  ...  1977181824              1\n",
              "2252  13-Dec-2017     2667.59  ...  1931148416              1\n",
              "2253  14-Dec-2017     2665.87  ...  1974812928              1\n",
              "2254  15-Dec-2017     2660.63  ...  3472946176              1\n",
              "2255  18-Dec-2017     2685.92  ...  2092151424              0\n",
              "2256  19-Dec-2017     2692.71  ...  1907656576              0\n",
              "2257  20-Dec-2017     2688.18  ...  1937403264              1\n",
              "2258  21-Dec-2017     2683.02  ...  1933795072              1\n",
              "2259  22-Dec-2017     2684.22  ...  1383888512              0\n",
              "2260  26-Dec-2017     2679.09  ...  1103808384              0\n",
              "2261  27-Dec-2017     2682.10  ...  1149108352              0\n",
              "2262  28-Dec-2017     2686.10  ...  1126089856              0\n",
              "2263  29-Dec-2017     2689.15  ...  1332374016              0\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHs0Pam0kkNZ",
        "colab_type": "code",
        "outputId": "852dccc9-6219-486c-ac0b-8b079507a590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "SP_test.tail(20)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open Price</th>\n",
              "      <th>Close Price</th>\n",
              "      <th>High Price</th>\n",
              "      <th>Low Price</th>\n",
              "      <th>Volume</th>\n",
              "      <th>fourday_trend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>03-Dec-2018</td>\n",
              "      <td>2790.50</td>\n",
              "      <td>2790.37</td>\n",
              "      <td>2800.18</td>\n",
              "      <td>2773.38</td>\n",
              "      <td>2549100288</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>04-Dec-2018</td>\n",
              "      <td>2782.43</td>\n",
              "      <td>2700.06</td>\n",
              "      <td>2785.93</td>\n",
              "      <td>2697.18</td>\n",
              "      <td>2813910016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>05-Dec-2018</td>\n",
              "      <td>2782.43</td>\n",
              "      <td>2700.06</td>\n",
              "      <td>2785.93</td>\n",
              "      <td>2697.18</td>\n",
              "      <td>2858957824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>06-Dec-2018</td>\n",
              "      <td>2663.51</td>\n",
              "      <td>2695.95</td>\n",
              "      <td>2696.15</td>\n",
              "      <td>2621.53</td>\n",
              "      <td>3115363584</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>07-Dec-2018</td>\n",
              "      <td>2691.26</td>\n",
              "      <td>2633.08</td>\n",
              "      <td>2708.54</td>\n",
              "      <td>2623.14</td>\n",
              "      <td>2457232384</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>10-Dec-2018</td>\n",
              "      <td>2630.86</td>\n",
              "      <td>2637.72</td>\n",
              "      <td>2647.51</td>\n",
              "      <td>2583.23</td>\n",
              "      <td>2434630656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>11-Dec-2018</td>\n",
              "      <td>2664.44</td>\n",
              "      <td>2636.78</td>\n",
              "      <td>2674.35</td>\n",
              "      <td>2621.30</td>\n",
              "      <td>2242852864</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>12-Dec-2018</td>\n",
              "      <td>2658.23</td>\n",
              "      <td>2651.07</td>\n",
              "      <td>2685.44</td>\n",
              "      <td>2650.26</td>\n",
              "      <td>2304548096</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>13-Dec-2018</td>\n",
              "      <td>2658.70</td>\n",
              "      <td>2650.54</td>\n",
              "      <td>2670.19</td>\n",
              "      <td>2637.27</td>\n",
              "      <td>2241559552</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>14-Dec-2018</td>\n",
              "      <td>2629.68</td>\n",
              "      <td>2599.95</td>\n",
              "      <td>2635.07</td>\n",
              "      <td>2593.84</td>\n",
              "      <td>2429752576</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>17-Dec-2018</td>\n",
              "      <td>2590.75</td>\n",
              "      <td>2545.94</td>\n",
              "      <td>2601.13</td>\n",
              "      <td>2530.54</td>\n",
              "      <td>2715525120</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>18-Dec-2018</td>\n",
              "      <td>2559.90</td>\n",
              "      <td>2546.16</td>\n",
              "      <td>2573.99</td>\n",
              "      <td>2528.71</td>\n",
              "      <td>2624934656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>19-Dec-2018</td>\n",
              "      <td>2547.05</td>\n",
              "      <td>2506.96</td>\n",
              "      <td>2585.29</td>\n",
              "      <td>2488.96</td>\n",
              "      <td>3223729408</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>20-Dec-2018</td>\n",
              "      <td>2496.77</td>\n",
              "      <td>2467.42</td>\n",
              "      <td>2509.63</td>\n",
              "      <td>2441.18</td>\n",
              "      <td>3429582848</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>21-Dec-2018</td>\n",
              "      <td>2465.38</td>\n",
              "      <td>2416.62</td>\n",
              "      <td>2504.41</td>\n",
              "      <td>2408.55</td>\n",
              "      <td>4560164352</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>24-Dec-2018</td>\n",
              "      <td>2400.56</td>\n",
              "      <td>2351.10</td>\n",
              "      <td>2410.34</td>\n",
              "      <td>2351.10</td>\n",
              "      <td>1662758784</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>26-Dec-2018</td>\n",
              "      <td>2363.12</td>\n",
              "      <td>2467.70</td>\n",
              "      <td>2467.76</td>\n",
              "      <td>2346.58</td>\n",
              "      <td>2611875072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>27-Dec-2018</td>\n",
              "      <td>2442.50</td>\n",
              "      <td>2488.83</td>\n",
              "      <td>2489.10</td>\n",
              "      <td>2397.94</td>\n",
              "      <td>2386466304</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>28-Dec-2018</td>\n",
              "      <td>2498.77</td>\n",
              "      <td>2485.74</td>\n",
              "      <td>2520.27</td>\n",
              "      <td>2472.89</td>\n",
              "      <td>2080726656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>31-Dec-2018</td>\n",
              "      <td>2498.94</td>\n",
              "      <td>2506.85</td>\n",
              "      <td>2509.24</td>\n",
              "      <td>2482.82</td>\n",
              "      <td>1912680064</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  Open Price  Close Price  ...  Low Price      Volume  fourday_trend\n",
              "232  03-Dec-2018     2790.50      2790.37  ...    2773.38  2549100288              0\n",
              "233  04-Dec-2018     2782.43      2700.06  ...    2697.18  2813910016              0\n",
              "234  05-Dec-2018     2782.43      2700.06  ...    2697.18  2858957824              0\n",
              "235  06-Dec-2018     2663.51      2695.95  ...    2621.53  3115363584              0\n",
              "236  07-Dec-2018     2691.26      2633.08  ...    2623.14  2457232384              1\n",
              "237  10-Dec-2018     2630.86      2637.72  ...    2583.23  2434630656              0\n",
              "238  11-Dec-2018     2664.44      2636.78  ...    2621.30  2242852864              0\n",
              "239  12-Dec-2018     2658.23      2651.07  ...    2650.26  2304548096              0\n",
              "240  13-Dec-2018     2658.70      2650.54  ...    2637.27  2241559552              0\n",
              "241  14-Dec-2018     2629.68      2599.95  ...    2593.84  2429752576              0\n",
              "242  17-Dec-2018     2590.75      2545.94  ...    2530.54  2715525120              0\n",
              "243  18-Dec-2018     2559.90      2546.16  ...    2528.71  2624934656              0\n",
              "244  19-Dec-2018     2547.05      2506.96  ...    2488.96  3223729408              0\n",
              "245  20-Dec-2018     2496.77      2467.42  ...    2441.18  3429582848              1\n",
              "246  21-Dec-2018     2465.38      2416.62  ...    2408.55  4560164352              1\n",
              "247  24-Dec-2018     2400.56      2351.10  ...    2351.10  1662758784              1\n",
              "248  26-Dec-2018     2363.12      2467.70  ...    2346.58  2611875072              0\n",
              "249  27-Dec-2018     2442.50      2488.83  ...    2397.94  2386466304              0\n",
              "250  28-Dec-2018     2498.77      2485.74  ...    2472.89  2080726656              0\n",
              "251  31-Dec-2018     2498.94      2506.85  ...    2482.82  1912680064              0\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WjkNwbQktEd",
        "colab_type": "code",
        "outputId": "ea51bc7d-06b3-4290-ead1-6cead5c6672a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "SP_train.info()\n",
        "print('-' * 50)\n",
        "SP_test.info()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2264 entries, 0 to 2263\n",
            "Data columns (total 7 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Date           2264 non-null   object \n",
            " 1   Open Price     2264 non-null   float64\n",
            " 2   Close Price    2264 non-null   float64\n",
            " 3   High Price     2264 non-null   float64\n",
            " 4   Low Price      2264 non-null   float64\n",
            " 5   Volume         2264 non-null   int64  \n",
            " 6   fourday_trend  2264 non-null   int64  \n",
            "dtypes: float64(4), int64(2), object(1)\n",
            "memory usage: 123.9+ KB\n",
            "--------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252 entries, 0 to 251\n",
            "Data columns (total 7 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Date           252 non-null    object \n",
            " 1   Open Price     252 non-null    float64\n",
            " 2   Close Price    252 non-null    float64\n",
            " 3   High Price     252 non-null    float64\n",
            " 4   Low Price      252 non-null    float64\n",
            " 5   Volume         252 non-null    int64  \n",
            " 6   fourday_trend  252 non-null    int64  \n",
            "dtypes: float64(4), int64(2), object(1)\n",
            "memory usage: 13.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zISA1Ae_k4O9",
        "colab_type": "code",
        "outputId": "97bcb4bb-0d68-410a-ebb2-a7cd75c16f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "SP_train.describe()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open Price</th>\n",
              "      <th>Close Price</th>\n",
              "      <th>High Price</th>\n",
              "      <th>Low Price</th>\n",
              "      <th>Volume</th>\n",
              "      <th>fourday_trend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2264.000000</td>\n",
              "      <td>2264.000000</td>\n",
              "      <td>2264.000000</td>\n",
              "      <td>2264.000000</td>\n",
              "      <td>2.264000e+03</td>\n",
              "      <td>2264.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1656.142686</td>\n",
              "      <td>1656.767562</td>\n",
              "      <td>1664.427054</td>\n",
              "      <td>1647.425128</td>\n",
              "      <td>2.948755e+09</td>\n",
              "      <td>0.590548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>485.292193</td>\n",
              "      <td>485.226120</td>\n",
              "      <td>484.808706</td>\n",
              "      <td>485.576116</td>\n",
              "      <td>1.351675e+09</td>\n",
              "      <td>0.491841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>679.280000</td>\n",
              "      <td>676.530000</td>\n",
              "      <td>695.270000</td>\n",
              "      <td>666.790000</td>\n",
              "      <td>5.181584e+08</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1238.602500</td>\n",
              "      <td>1239.337500</td>\n",
              "      <td>1246.695000</td>\n",
              "      <td>1227.587500</td>\n",
              "      <td>2.048980e+09</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1649.135000</td>\n",
              "      <td>1650.405000</td>\n",
              "      <td>1656.145000</td>\n",
              "      <td>1639.600000</td>\n",
              "      <td>2.506637e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2070.300000</td>\n",
              "      <td>2071.190000</td>\n",
              "      <td>2079.507500</td>\n",
              "      <td>2058.757500</td>\n",
              "      <td>3.373334e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2692.710000</td>\n",
              "      <td>2690.160000</td>\n",
              "      <td>2694.970000</td>\n",
              "      <td>2685.920000</td>\n",
              "      <td>9.120100e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Open Price  Close Price  ...        Volume  fourday_trend\n",
              "count  2264.000000  2264.000000  ...  2.264000e+03    2264.000000\n",
              "mean   1656.142686  1656.767562  ...  2.948755e+09       0.590548\n",
              "std     485.292193   485.226120  ...  1.351675e+09       0.491841\n",
              "min     679.280000   676.530000  ...  5.181584e+08       0.000000\n",
              "25%    1238.602500  1239.337500  ...  2.048980e+09       0.000000\n",
              "50%    1649.135000  1650.405000  ...  2.506637e+09       1.000000\n",
              "75%    2070.300000  2071.190000  ...  3.373334e+09       1.000000\n",
              "max    2692.710000  2690.160000  ...  9.120100e+09       1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nBqzb2dk_3S",
        "colab_type": "code",
        "outputId": "6242ebbb-07cb-486a-8fef-e5e2e3c8a332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "SP_test.describe()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open Price</th>\n",
              "      <th>Close Price</th>\n",
              "      <th>High Price</th>\n",
              "      <th>Low Price</th>\n",
              "      <th>Volume</th>\n",
              "      <th>fourday_trend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>2.520000e+02</td>\n",
              "      <td>252.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2747.910397</td>\n",
              "      <td>2746.030873</td>\n",
              "      <td>2762.747778</td>\n",
              "      <td>2730.143929</td>\n",
              "      <td>2.154050e+09</td>\n",
              "      <td>0.555556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>99.017479</td>\n",
              "      <td>100.251272</td>\n",
              "      <td>92.991345</td>\n",
              "      <td>106.490954</td>\n",
              "      <td>4.538626e+08</td>\n",
              "      <td>0.497893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2363.120000</td>\n",
              "      <td>2351.100000</td>\n",
              "      <td>2410.340000</td>\n",
              "      <td>2346.580000</td>\n",
              "      <td>9.516523e+08</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2689.465000</td>\n",
              "      <td>2690.512500</td>\n",
              "      <td>2705.847500</td>\n",
              "      <td>2663.677500</td>\n",
              "      <td>1.879841e+09</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2742.170000</td>\n",
              "      <td>2741.920000</td>\n",
              "      <td>2755.575000</td>\n",
              "      <td>2725.290000</td>\n",
              "      <td>2.063820e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2811.430000</td>\n",
              "      <td>2814.322500</td>\n",
              "      <td>2824.802500</td>\n",
              "      <td>2800.630000</td>\n",
              "      <td>2.341078e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2936.760000</td>\n",
              "      <td>2930.750000</td>\n",
              "      <td>2940.910000</td>\n",
              "      <td>2927.110000</td>\n",
              "      <td>4.560164e+09</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Open Price  Close Price  ...        Volume  fourday_trend\n",
              "count   252.000000   252.000000  ...  2.520000e+02     252.000000\n",
              "mean   2747.910397  2746.030873  ...  2.154050e+09       0.555556\n",
              "std      99.017479   100.251272  ...  4.538626e+08       0.497893\n",
              "min    2363.120000  2351.100000  ...  9.516523e+08       0.000000\n",
              "25%    2689.465000  2690.512500  ...  1.879841e+09       0.000000\n",
              "50%    2742.170000  2741.920000  ...  2.063820e+09       1.000000\n",
              "75%    2811.430000  2814.322500  ...  2.341078e+09       1.000000\n",
              "max    2936.760000  2930.750000  ...  4.560164e+09       1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6YeiRcH-Lv8",
        "colab_type": "text"
      },
      "source": [
        "# 切割資料\n",
        "\n",
        "**在train與test中都會把最後4筆資料去除，原因為在train資料內最後四筆**\n",
        "\n",
        "**是沒有對象可以比較的，因此結果都為0，所以才會拿掉。而test則是因為**\n",
        "\n",
        "**最後四筆沒辦法得知正確結果，故不知道預測出來的結果是否正確，因此**\n",
        "\n",
        "**在這邊也拿掉。**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWVdXu5E9O2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 除去資料後四筆\n",
        "\n",
        "SP_train = SP_train.iloc[:-4, :]\n",
        "SP_test = SP_test.iloc[:-4, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujj531MOLAOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建立訓練和資料集\n",
        "\n",
        "train_x = SP_train.drop(['fourday_trend', 'Date'], axis = 1)\n",
        "train_y = SP_train.fourday_trend\n",
        "\n",
        "test_x = SP_test.drop(['fourday_trend', 'Date'], axis = 1)\n",
        "test_y = SP_test.fourday_trend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdySZCqvKuec",
        "colab_type": "text"
      },
      "source": [
        "# 建立模型\n",
        "\n",
        "**以下分別建立Logistic Regression, Neural Network及Decition Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9cpnC14L2UH",
        "colab_type": "code",
        "outputId": "a73cc6c4-ab2b-4854-a417-e4bab5982344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logit = LogisticRegression()\n",
        "logit.fit(train_x, train_y)\n",
        "logit.pred = logit.predict(test_x)\n",
        "logit.score(test_x, test_y)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5645161290322581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmrHSptouSXD",
        "colab_type": "code",
        "outputId": "a5e79cba-62c6-4481-bfbc-52a05258111e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Confusion metrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(test_y, logit.pred)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0, 108],\n",
              "       [  0, 140]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9N2zqy7foFe",
        "colab_type": "code",
        "outputId": "1e6e6bb4-3338-407c-9013-a04d383d480c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Neural Network\n",
        "\n",
        "from keras import models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "\n",
        "nn = models.Sequential()\n",
        "nn.add(Dense(4, activation = 'relu', kernel_initializer = 'random_normal', input_dim = 5))\n",
        "\n",
        "nn.add(Dense(4, activation = 'relu', kernel_initializer = 'random_normal'))\n",
        "\n",
        "nn.add(Dense(1, activation = 'sigmoid', kernel_initializer = 'random_normal'))\n",
        "\n",
        "nn.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy'],\n",
        ")\n",
        "\n",
        "nn.fit(train_x, train_y, batch_size = 10, epochs = 100)\n",
        "\n",
        "accuracy = nn.evaluate(test_x, test_y)\n",
        "\n",
        "print('test accuracy:', accuracy)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2260/2260 [==============================] - 0s 154us/step - loss: 25061.4192 - accuracy: 0.5226\n",
            "Epoch 2/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 2243.4208 - accuracy: 0.5270\n",
            "Epoch 3/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 386.1663 - accuracy: 0.5748\n",
            "Epoch 4/100\n",
            "2260/2260 [==============================] - 0s 122us/step - loss: 0.6870 - accuracy: 0.5916\n",
            "Epoch 5/100\n",
            "2260/2260 [==============================] - 0s 110us/step - loss: 0.6842 - accuracy: 0.5916\n",
            "Epoch 6/100\n",
            "2260/2260 [==============================] - 0s 109us/step - loss: 0.6818 - accuracy: 0.5916\n",
            "Epoch 7/100\n",
            "2260/2260 [==============================] - 0s 109us/step - loss: 0.6800 - accuracy: 0.5916\n",
            "Epoch 8/100\n",
            "2260/2260 [==============================] - 0s 119us/step - loss: 0.6788 - accuracy: 0.5916\n",
            "Epoch 9/100\n",
            "2260/2260 [==============================] - 0s 108us/step - loss: 0.6779 - accuracy: 0.5916\n",
            "Epoch 10/100\n",
            "2260/2260 [==============================] - 0s 119us/step - loss: 0.6773 - accuracy: 0.5916\n",
            "Epoch 11/100\n",
            "2260/2260 [==============================] - 0s 116us/step - loss: 0.6769 - accuracy: 0.5916\n",
            "Epoch 12/100\n",
            "2260/2260 [==============================] - 0s 114us/step - loss: 0.6766 - accuracy: 0.5916\n",
            "Epoch 13/100\n",
            "2260/2260 [==============================] - 0s 118us/step - loss: 0.6765 - accuracy: 0.5916\n",
            "Epoch 14/100\n",
            "2260/2260 [==============================] - 0s 108us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 15/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 16/100\n",
            "2260/2260 [==============================] - 0s 114us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 17/100\n",
            "2260/2260 [==============================] - 0s 109us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 18/100\n",
            "2260/2260 [==============================] - 0s 110us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 19/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 20/100\n",
            "2260/2260 [==============================] - 0s 111us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 21/100\n",
            "2260/2260 [==============================] - 0s 117us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 22/100\n",
            "2260/2260 [==============================] - 0s 117us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 23/100\n",
            "2260/2260 [==============================] - 0s 123us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 24/100\n",
            "2260/2260 [==============================] - 0s 113us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 25/100\n",
            "2260/2260 [==============================] - 0s 110us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 26/100\n",
            "2260/2260 [==============================] - 0s 116us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 27/100\n",
            "2260/2260 [==============================] - 0s 116us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 28/100\n",
            "2260/2260 [==============================] - 0s 117us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 29/100\n",
            "2260/2260 [==============================] - 0s 131us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 30/100\n",
            "2260/2260 [==============================] - 0s 120us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 31/100\n",
            "2260/2260 [==============================] - 0s 117us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 32/100\n",
            "2260/2260 [==============================] - 0s 113us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 33/100\n",
            "2260/2260 [==============================] - 0s 113us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 34/100\n",
            "2260/2260 [==============================] - 0s 122us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 35/100\n",
            "2260/2260 [==============================] - 0s 132us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 36/100\n",
            "2260/2260 [==============================] - 0s 119us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 37/100\n",
            "2260/2260 [==============================] - 0s 111us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 38/100\n",
            "2260/2260 [==============================] - 0s 107us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 39/100\n",
            "2260/2260 [==============================] - 0s 118us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 40/100\n",
            "2260/2260 [==============================] - 0s 110us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 41/100\n",
            "2260/2260 [==============================] - 0s 118us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 42/100\n",
            "2260/2260 [==============================] - 0s 111us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 43/100\n",
            "2260/2260 [==============================] - 0s 113us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 44/100\n",
            "2260/2260 [==============================] - 0s 107us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 45/100\n",
            "2260/2260 [==============================] - 0s 108us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 46/100\n",
            "2260/2260 [==============================] - 0s 122us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 47/100\n",
            "2260/2260 [==============================] - 0s 141us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 48/100\n",
            "2260/2260 [==============================] - 0s 129us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 49/100\n",
            "2260/2260 [==============================] - 0s 135us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 50/100\n",
            "2260/2260 [==============================] - 0s 144us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 51/100\n",
            "2260/2260 [==============================] - 0s 129us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 52/100\n",
            "2260/2260 [==============================] - 0s 169us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 53/100\n",
            "2260/2260 [==============================] - 0s 181us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 54/100\n",
            "2260/2260 [==============================] - 0s 172us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 55/100\n",
            "2260/2260 [==============================] - 0s 202us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 56/100\n",
            "2260/2260 [==============================] - 0s 193us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 57/100\n",
            "2260/2260 [==============================] - 0s 200us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 58/100\n",
            "2260/2260 [==============================] - 0s 197us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 59/100\n",
            "2260/2260 [==============================] - 0s 181us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 60/100\n",
            "2260/2260 [==============================] - 0s 207us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 61/100\n",
            "2260/2260 [==============================] - 0s 214us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 62/100\n",
            "2260/2260 [==============================] - 0s 194us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 63/100\n",
            "2260/2260 [==============================] - 0s 161us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 64/100\n",
            "2260/2260 [==============================] - 0s 149us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 65/100\n",
            "2260/2260 [==============================] - 0s 142us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 66/100\n",
            "2260/2260 [==============================] - 0s 127us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 67/100\n",
            "2260/2260 [==============================] - 0s 129us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 68/100\n",
            "2260/2260 [==============================] - 0s 129us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 69/100\n",
            "2260/2260 [==============================] - 0s 134us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 70/100\n",
            "2260/2260 [==============================] - 0s 128us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 71/100\n",
            "2260/2260 [==============================] - 0s 141us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 72/100\n",
            "2260/2260 [==============================] - 0s 128us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 73/100\n",
            "2260/2260 [==============================] - 0s 132us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 74/100\n",
            "2260/2260 [==============================] - 0s 131us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 75/100\n",
            "2260/2260 [==============================] - 0s 129us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 76/100\n",
            "2260/2260 [==============================] - 0s 138us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 77/100\n",
            "2260/2260 [==============================] - 0s 134us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 78/100\n",
            "2260/2260 [==============================] - 0s 141us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 79/100\n",
            "2260/2260 [==============================] - 0s 132us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 80/100\n",
            "2260/2260 [==============================] - 0s 131us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 81/100\n",
            "2260/2260 [==============================] - 0s 127us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 82/100\n",
            "2260/2260 [==============================] - 0s 127us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 83/100\n",
            "2260/2260 [==============================] - 0s 125us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 84/100\n",
            "2260/2260 [==============================] - 0s 143us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 85/100\n",
            "2260/2260 [==============================] - 0s 123us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 86/100\n",
            "2260/2260 [==============================] - 0s 110us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 87/100\n",
            "2260/2260 [==============================] - 0s 108us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 88/100\n",
            "2260/2260 [==============================] - 0s 120us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 89/100\n",
            "2260/2260 [==============================] - 0s 116us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 90/100\n",
            "2260/2260 [==============================] - 0s 106us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 91/100\n",
            "2260/2260 [==============================] - 0s 108us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 92/100\n",
            "2260/2260 [==============================] - 0s 110us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 93/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 94/100\n",
            "2260/2260 [==============================] - 0s 117us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 95/100\n",
            "2260/2260 [==============================] - 0s 111us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 96/100\n",
            "2260/2260 [==============================] - 0s 118us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 97/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 98/100\n",
            "2260/2260 [==============================] - 0s 112us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "Epoch 99/100\n",
            "2260/2260 [==============================] - 0s 119us/step - loss: 0.6764 - accuracy: 0.5916\n",
            "Epoch 100/100\n",
            "2260/2260 [==============================] - 0s 111us/step - loss: 0.6763 - accuracy: 0.5916\n",
            "248/248 [==============================] - 0s 106us/step\n",
            "test accuracy: [0.6863613647799338, 0.5645161271095276]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6JC_5E6bNDv",
        "colab_type": "code",
        "outputId": "d6faeebf-5e33-4af2-c09f-80bf96cc1209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Decition Tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(train_x, train_y)\n",
        "tree.pred = tree.predict(test_x)\n",
        "tree.score(test_x, test_y)\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUxdGiWQcDbE",
        "colab_type": "code",
        "outputId": "6ed374fc-873b-46ca-e860-fc7d6338d1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 建立混淆矩陣\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(test_y, tree.pred)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 97,  11],\n",
              "       [113,  27]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTeRdo5wWUyT",
        "colab_type": "code",
        "outputId": "a1eb9843-d03f-45de-b191-7a45d425ae93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "source": [
        "#依據ROC curve來調整depth參數\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "depth_parameters = np.arange(1, 50)\n",
        "\n",
        "train_auc= []\n",
        "test_auc = []\n",
        "\n",
        "for test_depth in depth_parameters:\n",
        "  temp_model = DecisionTreeClassifier(max_depth = test_depth)\n",
        "  temp_model.fit(train_x, train_y)\n",
        "  train_predictions = temp_model.predict(train_x)\n",
        "  test_predictions = temp_model.predict(test_x)\n",
        "  false_positive_rate, true_positive_rate, thresholds = roc_curve(train_y, train_predictions)\n",
        "  auc_area = auc(false_positive_rate, true_positive_rate)\n",
        "  train_auc.append(auc_area)\n",
        "  false_positive_rate, true_positive_rate, thresholds = roc_curve(test_y, test_predictions)\n",
        "  auc_area = auc(false_positive_rate, true_positive_rate)\n",
        "  test_auc.append(auc_area)\n",
        "\n",
        "plt.figure(figsize = (14,10))\n",
        "plt.plot(depth_parameters, train_auc, 'b', label = 'Train AUC')\n",
        "plt.plot(depth_parameters, test_auc, 'r', label = 'Test AUC')\n",
        "plt.ylabel('AUC')\n",
        "plt.xlabel('depth parameter')\n",
        "plt.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhpEfUnPVYyV",
        "colab_type": "code",
        "outputId": "815d8c06-579c-494f-b306-3e75f7f5434c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Decition Tree(調參)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth = 4)\n",
        "tree.fit(train_x, train_y)\n",
        "tree.pred = tree.predict(test_x)\n",
        "tree.score(test_x, test_y)\n",
        "\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.592741935483871"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BtE0j-Fuq-i",
        "colab_type": "code",
        "outputId": "3b182766-fc74-4d92-ed12-0e7d8210e4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# 建立混淆矩陣\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(test_y, tree.pred)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[80, 28],\n",
              "       [73, 67]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGQsdJ87ci6P",
        "colab_type": "text"
      },
      "source": [
        "# Discuss\n",
        "\n",
        "**How did you preprocess this data?**\n",
        "\n",
        "**從資料探索中可以得知資料並不需要進行預處理，主要有幾個原因:**\n",
        "\n",
        "**1.資料並為缺失值**\n",
        "\n",
        "**2.資料並無類別數據需要處理**\n",
        "\n",
        "**3.資料單位相同不需要進行標準化**\n",
        "\n",
        "**Which classifier reaches the highest classification accuracy in this dataset? Why? Can this result remain if the data is different?**\n",
        "\n",
        "**這邊使用了Logistic Regression、Neural Network和Decision Tree，accuracy分別為0.5645、0.5645及0.5927，以Decision Tree的分類稍微準確一些。主要是因為原先的Decision Tree只有0.5的accuracy，我稍微調整了參數中的max_depth使他的accuracy提高一些。**\n",
        "\n",
        "**如果是一樣從S&P500爬下其他時間的資料，我認為預測結果會是差不多的，因為並不需要進行太多的預處理，目標的定義差別也不會太大，得出來的結果應該類似。**\n",
        "\n",
        "**How did you improve your classifiers?**\n",
        "\n",
        "**這邊我只針對Decision Tree進行調整參數讓他的預測效果更準確。主要是因為在Logistic Regression中，參數的調整幾乎沒有太大的差異跟意義，這邊就沒有動任何參數。再來是Neural Network，因為是第一次使用，不太曉得該怎麼動參數，所以這裡屬於能力上的不足。最後Decision Tree是根據了ROC curve和AUC來檢視max_depth為多少的時候，他的結果會是最棒的。這邊讓他從1-50去畫出AUC最後的結果，可以看到當在Test data中AUC差不多為4~6的時候，他的AUC會是最高的，所以最後選擇4作為我們max_depth參數的調整。**"
      ]
    }
  ]
}